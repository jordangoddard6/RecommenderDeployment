{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\emmaj\\Downloads\\shared_articles.csv\")\n",
    "\n",
    "# Drop columns with missing values or unnecessary columns for the recommender\n",
    "df = df.dropna(subset=['text'])  # Ensure 'text' column has no missing values\n",
    "\n",
    "# Drop columns that are not needed for the content-based recommender\n",
    "df_reduced = df[['contentId', 'title', 'text']]  # Only keep necessary columns\n",
    "\n",
    "# TF-IDF Vectorization on the 'text' column\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(df_reduced['text'])\n",
    "\n",
    "# Compute Cosine Similarity Matrix\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Recommendation function\n",
    "def get_recommendations(item_id, sim_matrix, n=10):\n",
    "    if item_id < 0 or item_id >= sim_matrix.shape[0]:\n",
    "        raise ValueError(f\"Item {item_id} is not in the similarity matrix.\")\n",
    "    \n",
    "    sim_scores = list(enumerate(sim_matrix[item_id]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    # Skip the first element since it is the item itself\n",
    "    top_similar = sim_scores[1:n+1]\n",
    "    rec_dict = {i[0]: i[1] for i in top_similar}\n",
    "    return rec_dict\n",
    "\n",
    "# Save only the necessary components in the model\n",
    "content_model = {\n",
    "    'tfidf_vectorizer': tfidf,\n",
    "    'cosine_similarity': cosine_sim,\n",
    "    'contentId_to_title': dict(zip(df_reduced['contentId'], df_reduced['title']))  # Map contentId to title for easy lookup\n",
    "}\n",
    "\n",
    "# Save the model to contentmodel.sav\n",
    "save_path = r\"C:\\Users\\emmaj\\Downloads\\contentmodel.sav\"\n",
    "with open(save_path, 'wb') as f:\n",
    "    pickle.dump(content_model, f)\n",
    "\n",
    "print(f\"Model has been saved to {save_path}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
